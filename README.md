# Transformers
En-zh transformers by pytorch  
The Transformer model from the [Attention is All You Need paper](https://arxiv.org/abs/1706.03762).  
The Transformer model code from the [pytorch-seq2seq](https://github.com/bentrevett/pytorch-seq2seq/blob/master/6%20-%20Attention%20is%20All%20You%20Need.ipynb).  
![image](https://github.com/wawales/Transformers/blob/master/Figure_1.png)
